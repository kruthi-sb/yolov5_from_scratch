{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# VISUALIZE INPUT TENSORS OF SHAPE: [batch_size, channels, height, width]\n",
    "\n",
    "# eg.\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# (example values) -> pixel values between 0 to 255\n",
    "tensor = torch.tensor([[\n",
    "    [[100,200], [40,170]],  # Red channel\n",
    "    [[150,6], [70,80]],  # Green channel\n",
    "    [[50,0], [255,150]]   # Blue channel\n",
    "]])\n",
    "\n",
    "# Convert to numpy and prepare for visualization\n",
    "image = tensor.squeeze(0)  # Remove batch dimension -> 3x2x2\n",
    "image = image.permute(1, 2, 0)  # Change to HxWxC format -> 2x2x3\n",
    "image = image.numpy()  # Convert to numpy array\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(image)\n",
    "plt.axis('off')  # Hide axes\n",
    "plt.title('2x2 RGB Image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to visualize tensors\n",
    "\n",
    "def plot_tensor(input):\n",
    "    # Convert to numpy and prepare for visualization\n",
    "    image = input.squeeze(0)  # Remove batch dimension\n",
    "    image = image.permute(1, 2, 0)  # Change to HxWxC format\n",
    "    image = image.numpy()  # Convert to numpy array\n",
    "\n",
    "    # Display the image\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')  # Hide axes\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  tensor([[[[1.0000e+00, 2.0000e+00, 3.0000e+00,  ..., 2.8000e+01,\n",
      "           2.9000e+01, 3.0000e+01],\n",
      "          [3.1000e+01, 3.2000e+01, 3.3000e+01,  ..., 5.8000e+01,\n",
      "           5.9000e+01, 6.0000e+01],\n",
      "          [6.1000e+01, 6.2000e+01, 6.3000e+01,  ..., 8.8000e+01,\n",
      "           8.9000e+01, 9.0000e+01],\n",
      "          ...,\n",
      "          [8.1100e+02, 8.1200e+02, 8.1300e+02,  ..., 8.3800e+02,\n",
      "           8.3900e+02, 8.4000e+02],\n",
      "          [8.4100e+02, 8.4200e+02, 8.4300e+02,  ..., 8.6800e+02,\n",
      "           8.6900e+02, 8.7000e+02],\n",
      "          [8.7100e+02, 8.7200e+02, 8.7300e+02,  ..., 8.9800e+02,\n",
      "           8.9900e+02, 9.0000e+02]],\n",
      "\n",
      "         [[9.0100e+02, 9.0200e+02, 9.0300e+02,  ..., 9.2800e+02,\n",
      "           9.2900e+02, 9.3000e+02],\n",
      "          [9.3100e+02, 9.3200e+02, 9.3300e+02,  ..., 9.5800e+02,\n",
      "           9.5900e+02, 9.6000e+02],\n",
      "          [9.6100e+02, 9.6200e+02, 9.6300e+02,  ..., 9.8800e+02,\n",
      "           9.8900e+02, 9.9000e+02],\n",
      "          ...,\n",
      "          [1.7110e+03, 1.7120e+03, 1.7130e+03,  ..., 1.7380e+03,\n",
      "           1.7390e+03, 1.7400e+03],\n",
      "          [1.7410e+03, 1.7420e+03, 1.7430e+03,  ..., 1.7680e+03,\n",
      "           1.7690e+03, 1.7700e+03],\n",
      "          [1.7710e+03, 1.7720e+03, 1.7730e+03,  ..., 1.7980e+03,\n",
      "           1.7990e+03, 1.8000e+03]],\n",
      "\n",
      "         [[1.8010e+03, 1.8020e+03, 1.8030e+03,  ..., 1.8280e+03,\n",
      "           1.8290e+03, 1.8300e+03],\n",
      "          [1.8310e+03, 1.8320e+03, 1.8330e+03,  ..., 1.8580e+03,\n",
      "           1.8590e+03, 1.8600e+03],\n",
      "          [1.8610e+03, 1.8620e+03, 1.8630e+03,  ..., 1.8880e+03,\n",
      "           1.8890e+03, 1.8900e+03],\n",
      "          ...,\n",
      "          [2.6110e+03, 2.6120e+03, 2.6130e+03,  ..., 2.6380e+03,\n",
      "           2.6390e+03, 2.6400e+03],\n",
      "          [2.6410e+03, 2.6420e+03, 2.6430e+03,  ..., 2.6680e+03,\n",
      "           2.6690e+03, 2.6700e+03],\n",
      "          [2.6710e+03, 2.6720e+03, 2.6730e+03,  ..., 2.6980e+03,\n",
      "           2.6990e+03, 2.7000e+03]]]])\n",
      "input shape:  torch.Size([1, 3, 30, 30])\n",
      "nearest interpolation:  tensor([[[[1.0000e+00, 1.0000e+00, 2.0000e+00,  ..., 2.9000e+01,\n",
      "           3.0000e+01, 3.0000e+01],\n",
      "          [1.0000e+00, 1.0000e+00, 2.0000e+00,  ..., 2.9000e+01,\n",
      "           3.0000e+01, 3.0000e+01],\n",
      "          [3.1000e+01, 3.1000e+01, 3.2000e+01,  ..., 5.9000e+01,\n",
      "           6.0000e+01, 6.0000e+01],\n",
      "          ...,\n",
      "          [8.4100e+02, 8.4100e+02, 8.4200e+02,  ..., 8.6900e+02,\n",
      "           8.7000e+02, 8.7000e+02],\n",
      "          [8.7100e+02, 8.7100e+02, 8.7200e+02,  ..., 8.9900e+02,\n",
      "           9.0000e+02, 9.0000e+02],\n",
      "          [8.7100e+02, 8.7100e+02, 8.7200e+02,  ..., 8.9900e+02,\n",
      "           9.0000e+02, 9.0000e+02]],\n",
      "\n",
      "         [[9.0100e+02, 9.0100e+02, 9.0200e+02,  ..., 9.2900e+02,\n",
      "           9.3000e+02, 9.3000e+02],\n",
      "          [9.0100e+02, 9.0100e+02, 9.0200e+02,  ..., 9.2900e+02,\n",
      "           9.3000e+02, 9.3000e+02],\n",
      "          [9.3100e+02, 9.3100e+02, 9.3200e+02,  ..., 9.5900e+02,\n",
      "           9.6000e+02, 9.6000e+02],\n",
      "          ...,\n",
      "          [1.7410e+03, 1.7410e+03, 1.7420e+03,  ..., 1.7690e+03,\n",
      "           1.7700e+03, 1.7700e+03],\n",
      "          [1.7710e+03, 1.7710e+03, 1.7720e+03,  ..., 1.7990e+03,\n",
      "           1.8000e+03, 1.8000e+03],\n",
      "          [1.7710e+03, 1.7710e+03, 1.7720e+03,  ..., 1.7990e+03,\n",
      "           1.8000e+03, 1.8000e+03]],\n",
      "\n",
      "         [[1.8010e+03, 1.8010e+03, 1.8020e+03,  ..., 1.8290e+03,\n",
      "           1.8300e+03, 1.8300e+03],\n",
      "          [1.8010e+03, 1.8010e+03, 1.8020e+03,  ..., 1.8290e+03,\n",
      "           1.8300e+03, 1.8300e+03],\n",
      "          [1.8310e+03, 1.8310e+03, 1.8320e+03,  ..., 1.8590e+03,\n",
      "           1.8600e+03, 1.8600e+03],\n",
      "          ...,\n",
      "          [2.6410e+03, 2.6410e+03, 2.6420e+03,  ..., 2.6690e+03,\n",
      "           2.6700e+03, 2.6700e+03],\n",
      "          [2.6710e+03, 2.6710e+03, 2.6720e+03,  ..., 2.6990e+03,\n",
      "           2.7000e+03, 2.7000e+03],\n",
      "          [2.6710e+03, 2.6710e+03, 2.6720e+03,  ..., 2.6990e+03,\n",
      "           2.7000e+03, 2.7000e+03]]]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# INTERPOLATION\n",
    "\n",
    "input = torch.arange(1, 2701, dtype=torch.float32).view(1, 3, 30, 30) \n",
    "# arange: is for creating a tensor with (eg. values from 1 to 12)\n",
    "# view: is for reshaping the tensor to 1x3x30x30 - [batch_size, channels, height, width]\n",
    "\n",
    "print(\"input: \", input)\n",
    "print(\"input shape: \", input.shape)\n",
    "\n",
    "m = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "res = m(input)\n",
    "# Upsample: is for resizing the input tensor - essentially, increasing the resolution of the image.\n",
    "# scale_factor: if 2, then the height and width of the image will be doubled.\n",
    "# mode: nearest - the nearest pixel value is used for the new pixels.\n",
    "# other modes: bilinear, bicubic, trilinear, etc\n",
    "\n",
    "print(\"nearest interpolation: \", res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[2, 2]' is invalid for input of size 12",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimshow(tensor\u001b[38;5;241m.\u001b[39mview(tensor\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m], tensor\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mnumpy(), cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m---> 12\u001b[0m \u001b[43mplot_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 9\u001b[0m, in \u001b[0;36mplot_tensor\u001b[1;34m(tensor)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_tensor\u001b[39m(tensor):\n\u001b[0;32m      6\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m    plots the visual representation of a tensor.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimshow(\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy(), cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[2, 2]' is invalid for input of size 12"
     ]
    }
   ],
   "source": [
    "# VISUALIZE INTERPOLATION\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_tensor(tensor):\n",
    "    \"\"\"\n",
    "    plots the visual representation of a tensor.\n",
    "    \"\"\"\n",
    "    plt.imshow(tensor.view(tensor.shape[-2], tensor.shape[-1]).numpy(), cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "plot_tensor(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
